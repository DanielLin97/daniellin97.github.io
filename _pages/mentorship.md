---
layout: archive
title: "Mentorship"
permalink: /mentorship/
author_profile: true
---

Working with Me ðŸ¤—
===
If you are a Computer Science student interested in working with me on topics related to Large Language Models, please feel free to send your CV via email. I take mentorship seriously, aiming to collaborate closely with my mentees rather than merely assigning tasks. Together, we can explore the following areas:
* Impactful Research
* Open-source Software Applications
* Recent advances in Multimodal ML, Online Trust & Safety, Information Retrieval, Fact-Checking, Large Language Models, Code Intelligence, etc.

I will co-mentor students with my academic partner [Ziyang Luo](https://chiyeunglaw.github.io/). If you want to get a sense of our work, you can read my papers. However, please keep in mind that we have a few constraints. Due to availability, we can only mentor a limited number of students at the same time. Some mentees are listed below:

* Yuwei Zhao, master student from Beihang University (BUAA). Finished Projects: CodeJudge-Eval: Can Large Language Models be Good Judges in Code Understanding?. Accepted by COLING 2025.

* Jianzhao Huang, master student from Beijing University of Posts and Telecommunications (BUPT). Finished Projects: Towards Low-Resource Harmful Meme Detection with LMM Agents. Accepted by EMNLP 2024.

* Shengkang Wang, master student from Beijing University of Posts and Telecommunications (BUPT). Finished Projects: MFC-Bench: Benchmarking Multimodal Fact-Checking with Large Vision-Language Models. Accepted by ICLR 2025 workshop.

* Zixin Chen, master student from Beijing University of Posts and Telecommunications (BUPT). Finished Projects: CofiPara: A Coarse-to-fine Paradigm for Multimodal Sarcasm Target Identification with Large Multimodal Models. Accepted by ACL 2024.

* Liangliang Chen, master student from Beijing University of Posts and Telecommunications (BUPT). Finished Projects: Dual-Scale Interest Extraction Framework with Self-Supervision for Sequential Recommendation. Accepted by ECAI 2023.
